"""–û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è JSON-–ø—Ä–æ–º—Ç–æ–≤ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–º—É —Ä–µ—Ñ–µ—Ä–µ–Ω—Å—É."""

from __future__ import annotations

import logging
import re
from decimal import Decimal
from typing import List, Optional, Tuple
from urllib.parse import quote_plus

from aiogram import F, Router
from aiogram.filters import StateFilter
from aiogram.fsm.context import FSMContext
from aiogram.types import CallbackQuery, Message, InlineKeyboardMarkup
from asgiref.sync import sync_to_async
from django.conf import settings

from botapp.business.balance import BalanceService, InsufficientBalanceError
from botapp.error_tracker import ErrorTracker
from botapp.keyboards import (
    get_cancel_keyboard,
    get_reference_prompt_mods_keyboard,
    get_reference_prompt_models_keyboard,
    get_video_models_keyboard,
)
from botapp.models import BotErrorEvent, AIModel, TgUser
from botapp.reference_prompt import (
    REFERENCE_PROMPT_PRICING_SLUG,
    REFERENCE_PROMPT_MODELS,
    ReferenceInputPayload,
    ReferencePromptService,
    get_reference_prompt_model,
)
from botapp.reference_prompt.pricing import (
    build_reference_prompt_price_line,
    get_reference_pricing_model_and_cost,
)
from botapp.states import BotStates
from botapp.business.pricing import get_base_price_tokens


logger = logging.getLogger(__name__)

router = Router()
service = ReferencePromptService()

URL_RE = re.compile(r"(https?://[^\s]+|www\.[^\s]+)", re.IGNORECASE)


def _chunk_plain_text(text: str, limit: int = 3500) -> List[str]:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ —Ä–µ–∂–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è Telegram."""
    if not text:
        return [""]
    return [text[i : i + limit] for i in range(0, len(text), limit)]


def _escape_html(text: str) -> str:
    """–≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç HTML-—Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã."""
    if not text:
        return ""
    return (
        text
        .replace("&", "&amp;")
        .replace("<", "&lt;")
        .replace(">", "&gt;")
    )


async def _build_intro_message() -> str:
    price_line = await build_reference_prompt_price_line()
    return (
        "üîó –°–∫–∏–Ω—å—Ç–µ –≤ –±–æ—Ç–∞ —Å—Å—ã–ª–∫—É –Ω–∞ –ª—é–±–æ–π Reels, Shorts, TikTok –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –≤ —á–∞—Ç –≤–∏–¥–µ–æ –∏ –ø–æ–ª—É—á–∏—Ç–µ –ø—Ä–æ–º—Ç "
        "–¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–æ—á–Ω–æ —Ç–∞–∫–æ–≥–æ –∂–µ –≤–∏–¥–µ–æ!\n\n"
        f"{price_line}"
    )


def _extract_urls(text: Optional[str]) -> List[str]:
    if not text:
        return []
    return list({match.group(0) for match in URL_RE.finditer(text)})


def _collect_reference_payload(message: Message) -> Optional[ReferenceInputPayload]:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–º—Ç–∞."""

    if message.photo:
        photo = message.photo[-1]
        return ReferenceInputPayload(
            input_type="photo",
            text=message.caption,
            caption=message.caption,
            urls=_extract_urls(message.caption),
            file_id=photo.file_id,
            file_unique_id=photo.file_unique_id,
            mime_type="image/jpeg",
            file_size=photo.file_size,
            width=photo.width,
            height=photo.height,
        )

    if message.video:
        video = message.video
        return ReferenceInputPayload(
            input_type="video",
            text=message.caption,
            caption=message.caption,
            urls=_extract_urls(message.caption),
            file_id=video.file_id,
            file_unique_id=video.file_unique_id,
            mime_type=video.mime_type or "video/mp4",
            file_size=video.file_size,
            width=video.width,
            height=video.height,
            duration=video.duration,
        )

    if message.animation:
        animation = message.animation
        return ReferenceInputPayload(
            input_type="video",
            text=message.caption,
            caption=message.caption,
            urls=_extract_urls(message.caption),
            file_id=animation.file_id,
            file_unique_id=animation.file_unique_id,
            mime_type=animation.mime_type or "video/mp4",
            file_size=animation.file_size,
            width=animation.width,
            height=animation.height,
            duration=animation.duration,
        )

    if message.document:
        document = message.document
        mime = document.mime_type or ""
        if mime.startswith("image/"):
            input_type = "photo"
        elif mime.startswith("video/"):
            input_type = "video"
        else:
            return None

        return ReferenceInputPayload(
            input_type=input_type,
            text=message.caption,
            caption=message.caption,
            urls=_extract_urls(message.caption),
            file_id=document.file_id,
            file_unique_id=document.file_unique_id,
            file_name=document.file_name,
            mime_type=mime,
            file_size=document.file_size,
        )

    if message.text:
        text = message.text.strip()
        urls = _extract_urls(text)
        input_type = "url" if urls else "text"
        return ReferenceInputPayload(
            input_type=input_type,
            text=text,
            caption=text,
            urls=urls,
            source_url=urls[0] if urls else None,
        )

    return None


# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–Ω–æ–ø–∫–∏ "–ü—Ä–æ–º—Ç –ø–æ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å—É" –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω –≤ global_commands.py
# —á—Ç–æ–±—ã —Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑ –ª—é–±–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è


@router.callback_query(StateFilter("*"), F.data.startswith("ref_prompt_model:"))
async def prompt_by_reference_select_model(callback: CallbackQuery, state: FSMContext):
    await callback.answer()
    
    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    await state.clear()

    slug = callback.data.split(":", maxsplit=1)[1]

    try:
        model = get_reference_prompt_model(slug)
    except KeyError:
        options = [(m.slug, m.title) for m in REFERENCE_PROMPT_MODELS.values()]
        await callback.message.answer(
            "‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—ã–±—Ä–∞—Ç—å –∏–∑ —Å–ø–∏—Å–∫–∞ –∑–∞–Ω–æ–≤–æ.",
            reply_markup=get_reference_prompt_models_keyboard(options),
        )
        return

    await state.update_data(reference_prompt_model=model.slug)

    intro_text = await _build_intro_message()
    await callback.message.answer(intro_text, reply_markup=get_cancel_keyboard())

    await state.set_state(BotStates.reference_prompt_wait_reference)


@router.message(BotStates.reference_prompt_wait_reference)
async def prompt_by_reference_collect(message: Message, state: FSMContext):
    payload = _collect_reference_payload(message)

    if not payload:
        await message.answer(
            "–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—Ñ–µ—Ä–µ–Ω—Å. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ –≤–∏–¥–µ–æ.",
            reply_markup=get_cancel_keyboard(),
        )
        return

    await state.update_data(reference_payload=payload.as_state())

    await message.answer(
        '‚úÖ –†–µ—Ñ–µ—Ä–µ–Ω—Å –ø–æ–ª—É—á–µ–Ω üôå\n\n–ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ —Å–æ–∑–¥–∞—Ç—å —Ç–æ—á–Ω–æ —Ç–∞–∫–æ–µ –∂–µ –≤–∏–¥–µ–æ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ç–æ –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –∫–Ω–æ–ø–∫—É "‚úÖ –ë–µ–∑ –ø—Ä–∞–≤–æ–∫".\n\n–ê –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –≤–Ω–µ—Å—Ç–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –≤–∏–¥–µ–æ –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –∫–Ω–æ–ø–∫—É "‚úèÔ∏è –í–Ω–µ—Å—Ç–∏ –ø—Ä–∞–≤–∫–∏".',
        reply_markup=get_reference_prompt_mods_keyboard(),
    )
    await state.set_state(BotStates.reference_prompt_confirm_mods)


@router.callback_query(F.data == "ref_prompt_mods:edit")
async def prompt_by_reference_mods_yes(callback: CallbackQuery, state: FSMContext):
    await callback.answer()
    await callback.message.answer("–ù–∞–ø–∏—à–∏ –ø—Ä–∞–≤–∫–∏ –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º üîß")
    await state.set_state(BotStates.reference_prompt_wait_mods)


@router.callback_query(F.data == "ref_prompt_mods:skip")
async def prompt_by_reference_mods_skip(callback: CallbackQuery, state: FSMContext):
    await callback.answer()
    await _start_prompt_generation(callback.message, state, modifications=None)


@router.message(BotStates.reference_prompt_wait_mods)
async def prompt_by_reference_receive_mods(message: Message, state: FSMContext):
    if not message.text:
        await message.answer("–û—Ç–ø—Ä–∞–≤—å—Ç–µ –ø—Ä–∞–≤–∫–∏ —Ç–µ–∫—Å—Ç–æ–º –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º üîß")
        return

    await state.update_data(reference_modifications=message.text.strip())
    await _start_prompt_generation(message, state, modifications=message.text.strip())


async def _start_prompt_generation(message: Message, state: FSMContext, modifications: Optional[str]) -> None:
    data = await state.get_data()

    model_slug = data.get("reference_prompt_model")
    payload_data = data.get("reference_payload")

    if not model_slug or not payload_data:
        await message.answer(
            "–ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—á–Ω–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞.",
            reply_markup=get_cancel_keyboard(),
        )
        await state.clear()
        return

    reference_payload = ReferenceInputPayload.from_state(payload_data)

    user = None
    try:
        user = await sync_to_async(TgUser.objects.get)(chat_id=message.from_user.id)
    except TgUser.DoesNotExist:
        # –§–æ–ª–±–µ–∫: –≤–¥—Ä—É–≥ chat_id –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç from_user (–≥—Ä—É–ø–ø—ã/–∫–∞–Ω–∞–ª—ã)
        try:
            user = await sync_to_async(TgUser.objects.get)(chat_id=message.chat.id)
        except TgUser.DoesNotExist:
            pass

    if not user:
        await message.answer(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –ù–∞–∂–º–∏—Ç–µ /start –≤ –±–æ—Ç–µ, —á—Ç–æ–±—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Ñ–∏–ª—å, –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.",
            reply_markup=get_cancel_keyboard(),
        )
        await state.clear()
        return

    try:
        await sync_to_async(BalanceService.ensure_balance)(user)
    except Exception as exc:  # pragma: no cover - —Ä–µ–¥–∫–∏–π —Å–ª—É—á–∞–π –ø—Ä–æ–±–ª–µ–º —Å –±–∞–ª–∞–Ω—Å–æ–º
        logger.exception("reference_prompt: failed to ensure balance: %s", exc)
        await message.answer(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≤–∞—à –±–∞–ª–∞–Ω—Å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑ –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ /start.",
            reply_markup=get_cancel_keyboard(),
        )
        await state.clear()
        return

    pricing_model, cost_tokens = await get_reference_pricing_model_and_cost()
    if not pricing_model or cost_tokens is None:
        await message.answer(
            "–°—Ç–æ–∏–º–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            reply_markup=get_cancel_keyboard(),
        )
        await state.clear()
        return

    can_generate, error_msg = await sync_to_async(BalanceService.check_can_generate)(
        user,
        pricing_model,
        total_cost_tokens=cost_tokens,
    )
    if not can_generate:
        await message.answer(
            f"‚ùå {error_msg}",
            reply_markup=get_cancel_keyboard(),
        )
        await state.clear()
        return

    charge_tx = None
    try:
        charge_tx = await sync_to_async(BalanceService.charge_for_generation)(
            user,
            pricing_model,
            quantity=1,
            total_cost_tokens=cost_tokens,
        )
    except InsufficientBalanceError as exc:
        await message.answer(str(exc), reply_markup=get_cancel_keyboard())
        await state.clear()
        return

    logger.info(
        "reference_prompt: handler start chat_id=%s user_id=%s model=%s input_type=%s mods=%s",
        message.chat.id,
        message.from_user.id if message.from_user else None,
        model_slug,
        reference_payload.input_type,
        bool(modifications),
    )

    await message.answer(
        "–°–æ–∑–¥–∞—é –ø—Ä–æ–º—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É —Ä–µ—Ñ–µ—Ä–µ–Ω—Å—É, –æ–∂–∏–¥–∞–π—Ç–µ –ø–∞—Ä—É –º–∏–Ω—É—Ç ‚è≥",
        reply_markup=get_cancel_keyboard(),
    )
    await state.set_state(BotStates.reference_prompt_processing)

    try:
        result = await service.generate_prompt(
            bot=message.bot,
            model_slug=model_slug,
            reference=reference_payload,
            modifications=modifications,
            user_context={
                "chat_id": message.chat.id,
                "user_id": message.from_user.id if message.from_user else None,
                "username": message.from_user.username if message.from_user else None,
            },
        )
        video_keyboard = await _build_video_models_keyboard()
    except Exception as exc:  # noqa: BLE001 - –ª–æ–≥–∏—Ä—É–µ–º –∏ –æ—Ç–≤–µ—á–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        logger.exception("Failed to build reference prompt: %s", exc)
        if charge_tx:
            try:
                await sync_to_async(BalanceService.refund_generation)(
                    user,
                    charge_tx,
                    reason="reference_prompt_failed",
                )
            except Exception as refund_exc:  # pragma: no cover - –ª–æ–≥–∏—Ä—É–µ–º —Å–±–æ–π –≤–æ–∑–≤—Ä–∞—Ç–∞
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –≤–µ—Ä–Ω—É—Ç—å —Ç–æ–∫–µ–Ω—ã –∑–∞ reference prompt: %s", refund_exc)
        error_message = str(exc).strip() or "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –ø—Ä–æ–º—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞ –∏–ª–∏ –ø—Ä–∏—à–ª–∏—Ç–µ –¥—Ä—É–≥–æ–π —Ä–µ—Ñ–µ—Ä–µ–Ω—Å."
        await message.answer(
            f"‚ùå {error_message}",
            reply_markup=get_cancel_keyboard(),
        )
        await ErrorTracker.alog(
            origin=BotErrorEvent.Origin.TELEGRAM,
            severity=BotErrorEvent.Severity.WARNING,
            handler="reference_prompt._start_prompt_generation",
            chat_id=message.chat.id,
            payload={
                "model_slug": model_slug,
                "has_reference": bool(reference_payload),
                "modifications": modifications,
            },
            exc=exc,
        )
        await state.set_state(BotStates.reference_prompt_wait_reference)
        return

    spent_label = f"{cost_tokens.quantize(Decimal('0.01')):.2f}" if cost_tokens is not None else "0.00"
    remaining_tokens = (
        Decimal(charge_tx.balance_after).quantize(Decimal("0.01")) if charge_tx else None
    )
    remaining_label = f"{remaining_tokens:.2f}" if remaining_tokens is not None else "‚Äî"

    prompt_text = result.prompt_text or ""
    prompt_escaped = _escape_html(prompt_text)
    prompt_formatted = f"<code>{prompt_escaped}</code>" if prompt_escaped else "‚Äî"

    result_message = (
        "‚úÖ –ì–æ—Ç–æ–≤–æ!\n\n"
        f"<b>–°–ø–∏—Å–∞–Ω–æ:</b> ‚ö°{spent_label} —Ç–æ–∫–µ–Ω–æ–≤\n"
        f"<b>–û—Å—Ç–∞–ª–æ—Å—å:</b> ‚ö°{remaining_label} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
        f"<b>–í–∞—à –ø—Ä–æ–º—Ç:</b>\n{prompt_formatted}"
    )

    # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ, —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏
    if len(result_message) <= 4000:
        await message.answer(result_message, reply_markup=video_keyboard, parse_mode="HTML")
    else:
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç–¥–µ–ª—å–Ω–æ, –∑–∞—Ç–µ–º –ø—Ä–æ–º—Ç —á–∞—Å—Ç—è–º–∏
        header = (
            "‚úÖ –ì–æ—Ç–æ–≤–æ!\n\n"
            f"<b>–°–ø–∏—Å–∞–Ω–æ:</b> ‚ö°{spent_label} —Ç–æ–∫–µ–Ω–æ–≤\n"
            f"<b>–û—Å—Ç–∞–ª–æ—Å—å:</b> ‚ö°{remaining_label} —Ç–æ–∫–µ–Ω–æ–≤\n\n"
            "<b>–í–∞—à –ø—Ä–æ–º—Ç:</b>"
        )
        await message.answer(header, reply_markup=video_keyboard, parse_mode="HTML")
        chunks = _chunk_plain_text(prompt_text, limit=3500)
        for chunk in chunks:
            chunk_escaped = _escape_html(chunk)
            await message.answer(f"<code>{chunk_escaped}</code>", parse_mode="HTML")

    await state.clear()
    await state.set_state(BotStates.main_menu)


async def _build_video_models_keyboard() -> Optional[InlineKeyboardMarkup]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç inline-–∫–Ω–æ–ø–∫–∏ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏ –≤–∏–¥–µ–æ, –∫–∞–∫ –≤ '–°–æ–∑–¥–∞—Ç—å –≤–∏–¥–µ–æ'."""

    models = await sync_to_async(list)(
        AIModel.objects.filter(type="video", is_active=True)
        .exclude(slug=REFERENCE_PROMPT_PRICING_SLUG)
        .order_by("order")
    )
    if not models:
        return None

    public_base_url = (getattr(settings, "PUBLIC_BASE_URL", None) or "").rstrip("/")

    kling_webapps = {}
    veo_webapps = {}
    sora_webapps = {}
    midjourney_video_webapps = {}
    runway_webapps = {}

    if public_base_url:
        for model in models:
            cost = await sync_to_async(get_base_price_tokens)(model)
            price_label = f"‚ö°{cost:.2f} —Ç–æ–∫–µ–Ω–æ–≤"

            if model.provider == "kling":
                default_duration = None
                if isinstance(model.default_params, dict):
                    try:
                        default_duration = int(model.default_params.get("duration") or 0)
                    except (TypeError, ValueError):
                        default_duration = None
                base_duration = default_duration if default_duration and default_duration > 0 else 10
                kling_webapps[model.slug] = (
                    f"{public_base_url}/kling/?"
                    f"model={quote_plus(model.slug)}&price={quote_plus(price_label)}"
                    f"&price_base_duration={quote_plus(str(base_duration))}"
                )

            if model.provider == "veo" or model.slug.startswith("veo"):
                veo_webapps[model.slug] = (
                    f"{public_base_url}/veo/?"
                    f"model={quote_plus(model.slug)}&price={quote_plus(price_label)}"
                    f"&max_prompt={quote_plus(str(model.max_prompt_length))}"
                )

            if model.provider == "openai" and model.slug.startswith("sora"):
                sora_webapps[model.slug] = (
                    f"{public_base_url}/sora2/?"
                    f"model={quote_plus(model.slug)}&price={quote_plus(price_label)}"
                )
            if model.provider == "midjourney":
                midjourney_video_webapps[model.slug] = (
                    f"{public_base_url}/midjourney_video/?"
                    f"model={quote_plus(model.slug)}&price={quote_plus(price_label)}"
                    f"&max_prompt={quote_plus(str(model.max_prompt_length))}"
                )
            if model.provider == "useapi":
                base_duration = None
                if isinstance(model.default_params, dict):
                    try:
                        base_duration = int(model.default_params.get("duration") or 0)
                    except (TypeError, ValueError):
                        base_duration = None
                base_duration = base_duration if base_duration and base_duration > 0 else 5
                api_model_name = model.api_model_name or model.slug
                runway_webapps[model.slug] = (
                    f"{public_base_url}/runway/?"
                    f"model={quote_plus(model.slug)}&price={quote_plus(price_label)}"
                    f"&price_base_duration={quote_plus(str(base_duration))}"
                    f"&api_model={quote_plus(api_model_name)}"
                    f"&max_prompt={quote_plus(str(model.max_prompt_length))}"
                )

    return get_video_models_keyboard(
        models,
        kling_webapps=kling_webapps,
        veo_webapps=veo_webapps,
        sora_webapps=sora_webapps,
        midjourney_video_webapps=midjourney_video_webapps,
        runway_webapps=runway_webapps,
    )
