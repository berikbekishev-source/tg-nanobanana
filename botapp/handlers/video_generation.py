"""
–û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ
"""
import asyncio
import base64
import json
from io import BytesIO
from typing import Any, Dict, List, Optional, Tuple

from aiogram import Router, F
from aiogram.filters import StateFilter
from aiogram.types import Message, CallbackQuery
from aiogram.fsm.context import FSMContext

from botapp.states import BotStates
from botapp.keyboards import (
    get_video_models_keyboard,
    get_video_format_keyboard,
    get_video_duration_keyboard,
    get_video_resolution_keyboard,
    get_cancel_keyboard,
    get_main_menu_inline_keyboard,
    get_generation_start_message
)
from botapp.models import TgUser, AIModel, GenRequest, BotErrorEvent
from botapp.business.generation import GenerationService
from botapp.business.balance import BalanceService, InsufficientBalanceError
from botapp.business.pricing import calculate_request_cost, get_base_price_tokens
from botapp.tasks import generate_video_task, extend_video_task
from botapp.providers.video.openai_sora import resolve_sora_dimensions
from asgiref.sync import sync_to_async
from botapp.services import supabase_upload_png
from botapp.error_tracker import ErrorTracker

router = Router()
START_MESSAGE_DELAY = 0.6


async def _send_generation_start_message(
    message: Message,
    text: str,
    *,
    delay: float = START_MESSAGE_DELAY,
) -> None:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å—Ç–∞—Ä—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π, —á—Ç–æ–±—ã —É—Å–ø–µ–ª–æ –∑–∞–∫—Ä—ã—Ç—å—Å—è WebApp."""
    await asyncio.sleep(delay)
    await message.answer(text, reply_markup=get_main_menu_inline_keyboard())


def _extract_duration_options(model: AIModel) -> Optional[List[int]]:
    """
    –í–µ—Ä–Ω—É—Ç—å —Å–ø–∏—Å–æ–∫ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π, –µ—Å–ª–∏ –æ–Ω–∏ –∑–∞–¥–∞–Ω—ã –≤ allowed_params.
    """
    allowed_params = model.allowed_params or {}
    duration_param = allowed_params.get("duration")

    raw_options: Optional[List[int]] = None
    if isinstance(duration_param, list):
        raw_options = duration_param
    elif isinstance(duration_param, dict):
        options = duration_param.get("options") or duration_param.get("values")
        if isinstance(options, list):
            raw_options = options

    if not raw_options and model.provider == "openai":
        raw_options = [4, 8, 12]

    if not raw_options:
        return None

    cleaned: List[int] = []
    for value in raw_options:
        try:
            ivalue = int(value)
        except (TypeError, ValueError):
            continue
        if ivalue > 0:
            cleaned.append(ivalue)

    if not cleaned:
        return None

    cleaned = sorted(set(cleaned))
    return cleaned


def _calculate_image_size_hint(
    *,
    supports_images: bool,
    is_sora: bool,
    resolution: Optional[str],
    aspect_ratio: Optional[str],
) -> Optional[Tuple[int, int]]:
    if not (supports_images and is_sora and resolution and aspect_ratio):
        return None
    return resolve_sora_dimensions(resolution, aspect_ratio)


def _format_image_hint_text(dimensions: Optional[Tuple[int, int]]) -> Optional[str]:
    if not dimensions:
        return None
    width, height = dimensions
    return (
        f"–†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å: {width}x{height}. "
        "–ï—Å–ª–∏ —Ä–∞–∑–º–µ—Ä –±—É–¥–µ—Ç –¥—Ä—É–≥–∏–º, –º—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—Ä–µ–∂–µ–º —Ü–µ–Ω—Ç—Ä –ø–æ–¥ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç."
    )


MAX_KLING_IMAGE_BYTES = 10 * 1024 * 1024


def _convert_to_png_bytes(raw: bytes, mime: Optional[str]) -> bytes:
    mime_value = (mime or "").lower()
    if mime_value == "image/png":
        return raw
    try:
        from PIL import Image
    except ImportError:
        return raw
    try:
        with Image.open(BytesIO(raw)) as img:
            buffer = BytesIO()
            img.save(buffer, format="PNG")
            return buffer.getvalue()
    except Exception:
        return raw


def _extract_public_url(upload_obj) -> Optional[str]:
    if isinstance(upload_obj, dict):
        return upload_obj.get("public_url") or upload_obj.get("publicUrl") or upload_obj.get("publicURL")
    return upload_obj

def _extract_allowed_aspect_ratios(model: AIModel) -> List[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏."""
    allowed: List[str] = []
    params = model.allowed_params or {}
    raw = params.get("aspect_ratio")
    if isinstance(raw, list):
        allowed = [str(v) for v in raw if v]
    elif isinstance(raw, dict):
        opts = raw.get("options") or raw.get("values")
        if isinstance(opts, list):
            allowed = [str(v) for v in opts if v]
    return [r.strip() for r in allowed if isinstance(r, str) and r.strip()]

MAX_VEO_IMAGE_BYTES = 5 * 1024 * 1024


def _parse_webapp_payload(raw: str) -> Optional[Dict[str, Any]]:
    """
    –ê–∫–∫—É—Ä–∞—Ç–Ω–æ –ø–∞—Ä—Å–∏–º web_app_data, —É—á–∏—Ç—ã–≤–∞—è —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –¥–≤–æ–π–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ.
    """
    decoded = raw or "{}"
    try:
        if isinstance(decoded, bytes):
            decoded = decoded.decode("utf-8", errors="ignore")
        if decoded.startswith('{\"') or decoded.startswith("{\'"):
            try:
                decoded = decoded.encode().decode("unicode_escape")
            except Exception:
                pass
        payload = json.loads(decoded)
        if isinstance(payload, str):
            try:
                payload = json.loads(payload)
            except Exception:
                return None
        return payload if isinstance(payload, dict) else None
    except Exception:
        return None


@router.message(StateFilter("*"), F.web_app_data)
async def handle_webapp_data_dispatcher(message: Message, state: FSMContext):
    """Dispatcher for all WebApp data - routes to specific handler based on 'kind' field."""
    # Parse the payload once
    try:
        raw_data = message.web_app_data.data or "{}"
        if isinstance(raw_data, bytes):
            raw_data = raw_data.decode("utf-8", errors="ignore")
        if raw_data.startswith('{\\"') or raw_data.startswith("{\\'"):
            try:
                raw_data = raw_data.encode().decode("unicode_escape")
            except Exception:
                pass
        payload = json.loads(raw_data)
        if isinstance(payload, str):
            try:
                payload = json.loads(payload)
            except Exception:
                pass
    except Exception:
        await message.answer(
            "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ–∫–Ω–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫. –û—Ç–∫—Ä–æ–π—Ç–µ –µ–≥–æ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.",
            reply_markup=get_cancel_keyboard(),
        )
        await state.clear()
        return

    # Route based on kind
    kind = payload.get("kind") if isinstance(payload, dict) else None
    if kind == "sora2_settings":
        await _handle_sora_webapp_data_impl(message, state, payload)
    elif kind == "kling_settings":
        await _handle_kling_webapp_data_impl(message, state, payload)
    elif kind == "veo_video_settings":
        await _handle_veo_webapp_data_impl(message, state, payload)
    # If kind doesn't match, silently ignore (other handlers may process it)


async def _handle_sora_webapp_data_impl(message: Message, state: FSMContext, payload: dict):
    """–ü—Ä–∏–Ω–∏–º–∞–µ–º –¥–∞–Ω–Ω—ã–µ Sora 2 WebApp –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é."""
    data = await state.get_data()
    model_slug = payload.get("modelSlug") or data.get("model_slug") or data.get("selected_model") or "sora2"

    try:
        model = await sync_to_async(AIModel.objects.get)(slug=model_slug, is_active=True)
    except AIModel.DoesNotExist:
        await message.answer(
            "–ú–æ–¥–µ–ª—å Sora –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –í—ã–±–µ—Ä–∏—Ç–µ –µ—ë –∑–∞–Ω–æ–≤–æ –∏–∑ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π.",
            reply_markup=get_main_menu_inline_keyboard(),
        )
        await state.clear()
        return

    if model.provider not in {"openai"}:
        await message.answer(
            "–≠—Ç–∞ WebApp —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å –º–æ–¥–µ–ª—å—é Sora 2.",
            reply_markup=get_main_menu_inline_keyboard(),
        )
        await state.clear()
        return

    await state.update_data(model_id=int(model.id), model_slug=str(model.slug), model_provider=str(model.provider))

    prompt = (payload.get("prompt") or "").strip()
    if not prompt:
        await message.answer("–í–≤–µ–¥–∏—Ç–µ –ø—Ä–æ–º—Ç –≤ –æ–∫–Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –µ—â—ë —Ä–∞–∑.", reply_markup=get_cancel_keyboard())
        return

    generation_type = (payload.get("generationType") or "text2video").lower()
    if generation_type not in {"text2video", "image2video"}:
        generation_type = "text2video"

    allowed_durations = []
    try:
        allowed_durations = model.allowed_params.get("duration") or []
    except Exception:
        allowed_durations = []

    try:
        duration_value = int(float(payload.get("duration") or payload.get("seconds") or 8))
    except (TypeError, ValueError):
        duration_value = 8
    duration_value = max(2, min(60, duration_value))
    if allowed_durations:
        try:
            values = allowed_durations if isinstance(allowed_durations, list) else allowed_durations.get("options") or []
            if values and duration_value not in values:
                duration_value = values[0]
        except Exception:
            pass

    aspect_ratio = (
        payload.get("aspectRatio")
        or payload.get("aspect_ratio")
        or (model.default_params or {}).get("aspect_ratio")
        or "16:9"
    )
    if aspect_ratio not in {"16:9", "9:16", "1:1"}:
        aspect_ratio = "16:9"

    quality_raw = (payload.get("quality") or "").lower()
    resolution = payload.get("resolution") or (model.default_params or {}).get("resolution") or "720p"
    if quality_raw == "hd":
        resolution = "1080p"
    elif quality_raw == "standard":
        resolution = "720p"
    resolution = resolution.lower()

    params = {
        "duration": duration_value,
        "aspect_ratio": aspect_ratio,
        "resolution": resolution,
    }

    source_media = {}
    if generation_type == "image2video":
        image_b64 = payload.get("imageData")
        if not image_b64:
            await message.answer(
                "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —Ä–µ–∂–∏–º–∞ Image ‚Üí Video.",
                reply_markup=get_cancel_keyboard(),
            )
            return
        try:
            raw = base64.b64decode(image_b64)
        except Exception:
            await message.answer(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –µ—â—ë —Ä–∞–∑.",
                reply_markup=get_cancel_keyboard(),
            )
            return
        if len(raw) > MAX_KLING_IMAGE_BYTES:
            await message.answer(
                "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ. –ú–∞–∫—Å–∏–º—É–º 10 –ú–ë.",
                reply_markup=get_cancel_keyboard(),
            )
            return

        mime = payload.get("imageMime") or "image/png"
        file_name = payload.get("imageName") or "image.png"
        png_bytes = _convert_to_png_bytes(raw, mime)
        try:
            upload_obj = await sync_to_async(supabase_upload_png)(png_bytes)
        except Exception as exc:  # pragma: no cover - —Å–µ—Ç—å/—Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            await ErrorTracker.alog(
                origin=BotErrorEvent.Origin.TELEGRAM,
                severity=BotErrorEvent.Severity.WARNING,
                handler="video_generation.handle_sora_webapp_data",
                chat_id=message.chat.id,
                payload={"reason": "supabase_upload_failed"},
                exc=exc,
            )
            await message.answer(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª.",
                reply_markup=get_cancel_keyboard(),
            )
            await state.clear()
            return

        image_url = _extract_public_url(upload_obj)
        if not image_url:
            await message.answer(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Å—ã–ª–∫—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.",
                reply_markup=get_cancel_keyboard(),
            )
            await state.clear()
            return

        params["image_url"] = image_url
        params["input_image_mime_type"] = mime
        source_media = {
            "file_name": file_name,
            "mime_type": mime,
            "storage_url": image_url,
            "size_bytes": len(raw),
            "source": "sora_webapp",
        }

    try:
        user = await sync_to_async(TgUser.objects.get)(chat_id=message.from_user.id)
    except TgUser.DoesNotExist:
        await message.answer(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –ù–∞—á–Ω–∏—Ç–µ –∑–∞–Ω–æ–≤–æ.",
            reply_markup=get_main_menu_inline_keyboard(),
        )
        await state.clear()
        return

    try:
        gen_request = await sync_to_async(GenerationService.create_generation_request)(
            user=user,
            ai_model=model,
            prompt=prompt,
            quantity=1,
            generation_type=generation_type,
            generation_params=params,
            duration=duration_value,
            video_resolution=resolution,
            aspect_ratio=aspect_ratio,
            source_media=source_media,
        )
    except InsufficientBalanceError as exc:
        await message.answer(str(exc), reply_markup=get_main_menu_inline_keyboard())
        await state.clear()
        return
    except ValueError as exc:
        await message.answer(str(exc), reply_markup=get_main_menu_inline_keyboard())
        await state.clear()
        return
    except Exception as exc:
        await message.answer(
            "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.",
            reply_markup=get_main_menu_inline_keyboard(),
        )
        await ErrorTracker.alog(
            origin=BotErrorEvent.Origin.TELEGRAM,
            severity=BotErrorEvent.Severity.ERROR,
            handler="video_generation.handle_sora_webapp_data",
            chat_id=message.chat.id,
            payload={
                "generation_type": generation_type,
                "duration": duration_value,
                "aspect_ratio": aspect_ratio,
                "resolution": resolution,
            },
            exc=exc,
        )
        await state.clear()
        return

    await _send_generation_start_message(
        message,
        get_generation_start_message(
            model=model.display_name,
            mode=generation_type,
            aspect_ratio=aspect_ratio,
            resolution=resolution,
            duration=duration_value,
            prompt=prompt,
        ),
    )

    generate_video_task.delay(gen_request.id)
    await state.clear()


async def _handle_kling_webapp_data_impl(message: Message, state: FSMContext, payload: dict):
    """–ü—Ä–∏–Ω–∏–º–∞–µ–º –¥–∞–Ω–Ω—ã–µ Kling WebApp –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é."""
    data = await state.get_data()
    model_slug = payload.get("modelSlug") or data.get("model_slug") or data.get("selected_model") or "kling-v1"
    try:
        model = await sync_to_async(AIModel.objects.get)(slug=model_slug, is_active=True)
    except AIModel.DoesNotExist:
        await message.answer(
            "–ú–æ–¥–µ–ª—å Kling –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –í—ã–±–µ—Ä–∏—Ç–µ –µ—ë –∑–∞–Ω–æ–≤–æ –∏–∑ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π.",
            reply_markup=get_main_menu_inline_keyboard(),
        )
        await state.clear()
        return
    if model.provider != "kling":
        await message.answer(
            "–≠—Ç–∞ WebApp —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å –º–æ–¥–µ–ª—å—é Kling. –í—ã–±–µ—Ä–∏—Ç–µ –µ—ë –∏–∑ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π.",
            reply_markup=get_main_menu_inline_keyboard(),
        )
        await state.clear()
        return
    await state.update_data(
        model_id=int(model.id),
        model_slug=str(model.slug),
        model_provider=str(model.provider),
        selected_model=str(model.slug),
    )

    prompt = (payload.get("prompt") or "").strip()
    if not prompt:
        await message.answer("–í–≤–µ–¥–∏—Ç–µ –ø—Ä–æ–º—Ç –≤ –æ–∫–Ω–µ Kling –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –µ—â—ë —Ä–∞–∑.", reply_markup=get_cancel_keyboard())
        return
    if len(prompt) > model.max_prompt_length:
        await message.answer(
            f"‚ùå –ü—Ä–æ–º—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π! –ú–∞–∫—Å–∏–º—É–º {model.max_prompt_length} —Å–∏–º–≤–æ–ª–æ–≤.",
            reply_markup=get_cancel_keyboard(),
        )
        return

    try:
        user = await sync_to_async(TgUser.objects.get)(chat_id=message.from_user.id)
    except TgUser.DoesNotExist:
        await message.answer(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –ù–∞—á–Ω–∏—Ç–µ –∑–∞–Ω–æ–≤–æ.",
            reply_markup=get_main_menu_inline_keyboard(),
        )
        await state.clear()
        return

    try:
        cost_tokens = await sync_to_async(get_base_price_tokens)(model)
        can_generate, error_msg = await sync_to_async(BalanceService.check_can_generate)(
            user,
            model,
            total_cost_tokens=cost_tokens,
        )
        if not can_generate:
            await message.answer(
                f"‚ùå {error_msg}",
                reply_markup=get_main_menu_inline_keyboard(),
            )
            await state.clear()
            return
    except Exception:
        # –ü—Ä–æ–≤–µ—Ä–∫—É –±–∞–ª–∞–Ω—Å–∞ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–∏ –æ—à–∏–±–∫–µ ‚Äî —Å–µ—Ä–≤–∏—Å –ø—Ä–æ–≤–µ—Ä–∏—Ç –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º –∑–∞–¥–∞—á–∏
        pass

    generation_type = (payload.get("generationType") or "text2video").lower()
    if generation_type not in {"text2video", "image2video"}:
        generation_type = "text2video"

    try:
        duration_raw = payload.get("duration")
        duration_value = int(float(duration_raw))
    except (TypeError, ValueError):
        duration_value = 5
    if duration_value not in {5, 10}:
        duration_value = 5

    cfg_scale_value = payload.get("cfgScale")
    try:
        cfg_scale_value = max(0.0, min(1.0, round(float(cfg_scale_value), 1)))
    except (TypeError, ValueError):
        cfg_scale_value = 0.5

    defaults = model.default_params or {}
    allowed_aspects = _extract_allowed_aspect_ratios(model) or ["16:9", "9:16", "1:1"]
    requested_aspect = (
        payload.get("aspectRatio")
        or payload.get("aspect_ratio")
        or defaults.get("aspect_ratio")
        or "16:9"
    )
    fallback_aspect = defaults.get("aspect_ratio")
    if fallback_aspect not in allowed_aspects:
        fallback_aspect = allowed_aspects[0]
    aspect_ratio = requested_aspect if requested_aspect in allowed_aspects else fallback_aspect

    params = {
        "duration": duration_value,
        "cfg_scale": cfg_scale_value,
        "aspect_ratio": aspect_ratio,
    }

    source_media = None

    if generation_type == "image2video":
        image_b64 = payload.get("imageData")
        if not image_b64:
            await message.answer(
                "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ WebApp –¥–ª—è —Ä–µ–∂–∏–º–∞ Image ‚Üí Video.",
                reply_markup=get_cancel_keyboard(),
            )
            return
        try:
            raw = base64.b64decode(image_b64)
        except Exception:
            await message.answer(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –µ—â—ë —Ä–∞–∑.",
                reply_markup=get_cancel_keyboard(),
            )
            return

        if len(raw) > MAX_KLING_IMAGE_BYTES:
            await message.answer(
                "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ. –ú–∞–∫—Å–∏–º—É–º 10 –ú–ë.",
                reply_markup=get_cancel_keyboard(),
            )
            return

        mime = payload.get("imageMime") or "image/png"
        file_name = payload.get("imageName") or "image.png"

        png_bytes = _convert_to_png_bytes(raw, mime)
        try:
            upload_obj = await sync_to_async(supabase_upload_png)(png_bytes)
        except Exception as exc:  # pragma: no cover - —Å–µ—Ç—å/—Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            await ErrorTracker.alog(
                origin=BotErrorEvent.Origin.TELEGRAM,
                severity=BotErrorEvent.Severity.WARNING,
                handler="video_generation.handle_kling_webapp_data",
                chat_id=message.chat.id,
                payload={"reason": "supabase_upload_failed"},
                exc=exc,
            )
            await message.answer(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª.",
                reply_markup=get_cancel_keyboard(),
            )
            await state.clear()
            return

        image_url = _extract_public_url(upload_obj)
        if not image_url:
            await message.answer(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Å—ã–ª–∫—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.",
                reply_markup=get_cancel_keyboard(),
            )
            await state.clear()
            return

        params["image_url"] = image_url
        source_media = {
            "file_name": file_name,
            "mime_type": mime,
            "storage_url": image_url,
            "size_bytes": len(raw),
            "source": "kling_webapp",
        }

    try:
        gen_request = await sync_to_async(GenerationService.create_generation_request)(
            user=user,
            ai_model=model,
            prompt=prompt,
            quantity=1,
            generation_type=generation_type,
            generation_params=params,
            duration=duration_value,
            aspect_ratio=aspect_ratio,
            source_media=source_media,
        )
    except InsufficientBalanceError as exc:
        await message.answer(str(exc), reply_markup=get_main_menu_inline_keyboard())
        await state.clear()
        return
    except ValueError as exc:
        await message.answer(str(exc), reply_markup=get_main_menu_inline_keyboard())
        await state.clear()
        return
    except Exception as exc:
        await message.answer(
            "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.",
            reply_markup=get_main_menu_inline_keyboard(),
        )
        await ErrorTracker.alog(
            origin=BotErrorEvent.Origin.TELEGRAM,
            severity=BotErrorEvent.Severity.ERROR,
            handler="video_generation.handle_kling_webapp_data",
            chat_id=message.chat.id,
            payload={
                "generation_type": generation_type,
                "duration": duration_value,
                "aspect_ratio": aspect_ratio,
            },
            exc=exc,
        )
        await state.clear()
        return

    await _send_generation_start_message(
        message,
        get_generation_start_message(
            model=model.display_name,
            mode=generation_type,
            aspect_ratio=aspect_ratio,
            resolution=None,
            duration=duration_value,
            prompt=prompt,
        ),
    )

    generate_video_task.delay(gen_request.id)
    await state.clear()


async def _handle_veo_webapp_data_impl(message: Message, state: FSMContext, payload: dict):
    """–ü—Ä–∏–Ω–∏–º–∞–µ–º –¥–∞–Ω–Ω—ã–µ Veo WebApp –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é."""
    data = await state.get_data()
    model_slug = payload.get("modelSlug") or data.get("model_slug") or data.get("selected_model") or "veo3-fast"

    try:
        model = await sync_to_async(AIModel.objects.get)(slug=model_slug, is_active=True)
    except AIModel.DoesNotExist:
        await message.answer(
            "–ú–æ–¥–µ–ª—å Veo –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –í—ã–±–µ—Ä–∏—Ç–µ –µ—ë –∑–∞–Ω–æ–≤–æ –∏–∑ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π.",
            reply_markup=get_main_menu_inline_keyboard(),
        )
        await state.clear()
        return

    if model.provider != "veo":
        await message.answer(
            "–≠—Ç–∞ WebApp —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å –º–æ–¥–µ–ª—å—é Veo. –í—ã–±–µ—Ä–∏—Ç–µ –µ—ë –∏–∑ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π.",
            reply_markup=get_main_menu_inline_keyboard(),
        )
        await state.clear()
        return

    await state.update_data(model_id=int(model.id), model_slug=str(model.slug), model_provider=str(model.provider))

    params_payload = payload.get("params") if isinstance(payload.get("params"), dict) else {}

    prompt = (payload.get("prompt") or params_payload.get("prompt") or "").strip()
    if not prompt:
        await message.answer("–í–≤–µ–¥–∏—Ç–µ –ø—Ä–æ–º—Ç –≤ –æ–∫–Ω–µ Veo –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –µ—â—ë —Ä–∞–∑.", reply_markup=get_cancel_keyboard())
        return
    if len(prompt) > model.max_prompt_length:
        await message.answer(
            f"‚ùå –ü—Ä–æ–º—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π! –ú–∞–∫—Å–∏–º—É–º {model.max_prompt_length} —Å–∏–º–≤–æ–ª–æ–≤.",
            reply_markup=get_cancel_keyboard(),
        )
        return

    mode_value = (payload.get("mode") or params_payload.get("mode") or "text2video").lower()
    generation_type = "image2video" if mode_value == "image2video" else "text2video"

    defaults = model.default_params or {}
    aspect_ratio = (
        params_payload.get("aspectRatio")
        or params_payload.get("aspect_ratio")
        or payload.get("aspectRatio")
        or payload.get("aspect_ratio")
        or data.get("default_aspect_ratio")
        or defaults.get("aspect_ratio")
        or "9:16"
    )
    allowed_ratios = _extract_allowed_aspect_ratios(model) or ["9:16", "16:9", "1:1"]
    if aspect_ratio not in allowed_ratios:
        aspect_ratio = allowed_ratios[0]

    duration = data.get("default_duration") or defaults.get("duration") or 8
    resolution = data.get("default_resolution") or defaults.get("resolution") or "720p"

    input_images = []
    final_frame = None

    def _prepare_inline_image(raw_b64, mime, name):
        if not raw_b64:
            raise ValueError("missing")
        try:
            decoded = base64.b64decode(raw_b64)
        except Exception as exc:
            raise ValueError("decode") from exc
        if len(decoded) > MAX_VEO_IMAGE_BYTES:
            raise ValueError("too_large")
        normalized = base64.b64encode(decoded).decode("ascii")
        return {
            "content_base64": normalized,
            "mime_type": mime or "image/png",
            "filename": name or "image.png",
        }

    if generation_type == "image2video":
        start_raw = (
            params_payload.get("startImage")
            or params_payload.get("start_image")
            or payload.get("startImage")
            or payload.get("start_image")
        )
        start_mime = (
            params_payload.get("startImageMime")
            or params_payload.get("start_image_mime")
            or payload.get("startImageMime")
            or payload.get("start_image_mime")
        )
        start_name = (
            params_payload.get("startImageName")
            or params_payload.get("start_image_name")
            or payload.get("startImageName")
            or payload.get("start_image_name")
        )

        if not start_raw:
            await message.answer("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –Ω–∞—á–∞–ª—å–Ω—ã–π –∫–∞–¥—Ä (–¥–æ 5 –ú–ë).", reply_markup=get_cancel_keyboard())
            return

        try:
            start_image = _prepare_inline_image(start_raw, start_mime, start_name)
        except ValueError as exc:
            reason = str(exc)
            if reason == "too_large":
                await message.answer(
                    "–ù–∞—á–∞–ª—å–Ω—ã–π –∫–∞–¥—Ä –ø—Ä–µ–≤—ã—à–∞–µ—Ç 5 –ú–ë. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –ø–æ–º–µ–Ω—å—à–µ.",
                    reply_markup=get_cancel_keyboard(),
                )
            else:
                await message.answer(
                    "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –Ω–∞—á–∞–ª—å–Ω—ã–π –∫–∞–¥—Ä. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥—Ä—É–≥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.",
                    reply_markup=get_cancel_keyboard(),
                )
            return

        input_images.append(start_image)

        end_raw = (
            params_payload.get("endImage")
            or params_payload.get("end_image")
            or payload.get("endImage")
            or payload.get("end_image")
        )
        if end_raw:
            end_mime = (
                params_payload.get("endImageMime")
                or params_payload.get("end_image_mime")
                or payload.get("endImageMime")
                or payload.get("end_image_mime")
            )
            end_name = (
                params_payload.get("endImageName")
                or params_payload.get("end_image_name")
                or payload.get("endImageName")
                or payload.get("end_image_name")
            )

            try:
                final_frame = _prepare_inline_image(end_raw, end_mime, end_name)
            except ValueError as exc:
                reason = str(exc)
                if reason == "too_large":
                    await message.answer(
                        "–ö–æ–Ω–µ—á–Ω—ã–π –∫–∞–¥—Ä –ø—Ä–µ–≤—ã—à–∞–µ—Ç 5 –ú–ë. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –ø–æ–º–µ–Ω—å—à–µ –∏–ª–∏ –æ—Å—Ç–∞–≤—å—Ç–µ –ø–æ–ª–µ –ø—É—Å—Ç—ã–º.",
                        reply_markup=get_cancel_keyboard(),
                    )
                else:
                    await message.answer(
                        "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–æ–Ω–µ—á–Ω—ã–π –∫–∞–¥—Ä. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª –∏–ª–∏ –æ—Å—Ç–∞–≤—å—Ç–µ –ø–æ–ª–µ –ø—É—Å—Ç—ã–º.",
                        reply_markup=get_cancel_keyboard(),
                    )
                return

    generation_params = {
        "duration": duration,
        "resolution": resolution,
        "aspect_ratio": aspect_ratio,
    }
    if final_frame:
        generation_params["final_frame"] = final_frame

    try:
        user = await sync_to_async(TgUser.objects.get)(chat_id=message.from_user.id)
    except TgUser.DoesNotExist:
        await message.answer(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –ù–∞—á–Ω–∏—Ç–µ –∑–∞–Ω–æ–≤–æ.",
            reply_markup=get_main_menu_inline_keyboard(),
        )
        await state.clear()
        return

    try:
        _, cost_tokens = await sync_to_async(calculate_request_cost)(
            model, quantity=1, duration=duration, params=generation_params
        )
        can_generate, error_msg = await sync_to_async(BalanceService.check_can_generate)(
            user, model, quantity=1, total_cost_tokens=cost_tokens
        )
        if not can_generate:
            await message.answer(
                f"‚ùå {error_msg}",
                reply_markup=get_main_menu_inline_keyboard(),
            )
            await state.clear()
            return
    except Exception as exc:
        await message.answer(
            "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –±–∞–ª–∞–Ω—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            reply_markup=get_main_menu_inline_keyboard(),
        )
        await ErrorTracker.alog(
            origin=BotErrorEvent.Origin.TELEGRAM,
            severity=BotErrorEvent.Severity.WARNING,
            handler="video_generation.handle_veo_webapp_data.balance_check",
            chat_id=message.chat.id,
            payload={"model": model.slug},
            exc=exc,
        )
        await state.clear()
        return

    try:
        gen_request = await sync_to_async(GenerationService.create_generation_request)(
            user=user,
            ai_model=model,
            prompt=prompt,
            quantity=1,
            generation_type=generation_type,
            input_images=input_images,
            generation_params=generation_params,
            duration=duration,
            video_resolution=resolution,
            aspect_ratio=aspect_ratio,
        )
    except InsufficientBalanceError as exc:
        await message.answer(str(exc), reply_markup=get_main_menu_inline_keyboard())
        await state.clear()
        return
    except ValueError as exc:
        await message.answer(str(exc), reply_markup=get_main_menu_inline_keyboard())
        await state.clear()
        return
    except Exception as exc:
        await message.answer(
            "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.",
            reply_markup=get_main_menu_inline_keyboard(),
        )
        await ErrorTracker.alog(
            origin=BotErrorEvent.Origin.TELEGRAM,
            severity=BotErrorEvent.Severity.ERROR,
            handler="video_generation.handle_veo_webapp_data",
            chat_id=message.chat.id,
            payload={
                "generation_type": generation_type,
                "duration": duration,
                "aspect_ratio": aspect_ratio,
            },
            exc=exc,
        )
        await state.clear()
        return

    await _send_generation_start_message(
        message,
        get_generation_start_message(
            model=model.display_name,
            mode=generation_type,
            aspect_ratio=aspect_ratio,
            resolution=resolution,
            duration=duration,
            prompt=prompt,
        ),
    )

    generate_video_task.delay(gen_request.id)
    await state.clear()


async def _prompt_user_for_description(
    message: Message,
    *,
    supports_images: bool,
    aspect_ratio: str,
    duration: Optional[int],
    resolution: Optional[str] = None,
    is_sora: bool = False,
) -> None:
    """–û—Ç–ø—Ä–∞–≤–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –≤–≤–æ–¥—É –ø—Ä–æ–º—Ç–∞."""
    image_hint = _calculate_image_size_hint(
        supports_images=supports_images,
        is_sora=is_sora,
        resolution=resolution,
        aspect_ratio=aspect_ratio,
    )
    size_hint = _format_image_hint_text(image_hint) if supports_images else ""

    segments = [
        "‚úçÔ∏è  –ù–∞–ø–∏—à–∏ –≤ —á–∞—Ç –ø—Ä–æ–º—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞.",
        "üñº –ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≤ —á–∞—Ç –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ + —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º—Ç."
        f" {size_hint}".strip(),
        f"–§–æ—Ä–º–∞—Ç –≤—ã–±—Ä–∞–Ω: {aspect_ratio}",
    ]
    if duration:
        segments.append(f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration} —Å–µ–∫.")
    if resolution:
        segments.append(f"–ö–∞—á–µ—Å—Ç–≤–æ: {resolution.lower()}")

    intro = ["\n\n".join(segments)]

    await message.answer(
        "\n".join(intro),
        reply_markup=get_cancel_keyboard()
    )


async def _maybe_prompt_resolution(message: Message, state: FSMContext) -> bool:
    """
    –ü–æ–ø—Ä–æ—Å–∏—Ç—å –≤—ã–±—Ä–∞—Ç—å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ, –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è (Sora).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ –ø–æ–∫–∞–∑–∞–ª–∏ –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –≤—ã–±–æ—Ä–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è.
    """
    data = await state.get_data()
    if not data.get('is_sora'):
        return False
    options = data.get('resolution_options') or []
    selected_resolution = data.get('selected_resolution')
    if not options or selected_resolution:
        return False

    await state.set_state(BotStates.video_select_resolution)
    await message.answer(
        "–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ:\n"
        "‚Ä¢ 720p ‚Äî –±—ã—Å—Ç—Ä–µ–µ –∏ –¥–µ—à–µ–≤–ª–µ\n"
        "‚Ä¢ 1080p ‚Äî –≤—ã—à–µ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è",
        reply_markup=get_video_resolution_keyboard(options),
    )
    return True


# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–Ω–æ–ø–∫–∏ "üé¨ –°–æ–∑–¥–∞—Ç—å –≤–∏–¥–µ–æ" –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω –≤ global_commands.py
# —á—Ç–æ–±—ã —Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑ –ª—é–±–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏ "vid_model:" —Ç–∞–∫–∂–µ –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω –≤ global_commands.py
# —á—Ç–æ–±—ã —Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑ –ª—é–±–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è


@router.message(BotStates.video_select_format)
async def wait_format_selection(message: Message, state: FSMContext):
    """–ù–∞–ø–æ–º–∏–Ω–∞–µ–º –≤—ã–±—Ä–∞—Ç—å —Ñ–æ—Ä–º–∞—Ç, –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–ø—Ä–∞–≤–∏–ª —á—Ç–æ-—Ç–æ —Ä–∞–Ω—å—à–µ –≤—Ä–µ–º–µ–Ω–∏."""
    await message.answer(
        "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ä–º–∞—Ç –≤–∏–¥–µ–æ, –∏—Å–ø–æ–ª—å–∑—É—è –∫–Ω–æ–ø–∫–∏ –Ω–∏–∂–µ.",
        reply_markup=get_video_format_keyboard()
    )


@router.message(BotStates.video_select_duration)
async def wait_duration_selection(message: Message, state: FSMContext):
    """–ù–∞–ø–æ–º–∏–Ω–∞–µ–º –≤—ã–±—Ä–∞—Ç—å –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–ø—Ä–∞–≤–∏–ª —á—Ç–æ-—Ç–æ —Ä–∞–Ω—å—à–µ –≤—Ä–µ–º–µ–Ω–∏."""
    data = await state.get_data()
    duration_options = data.get('duration_options') or []
    if not duration_options:
        duration_options = [data.get('default_duration', 8)]
    await message.answer(
        "–í—ã–±–µ—Ä–∏—Ç–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–æ–ª–∏–∫–∞, –∏—Å–ø–æ–ª—å–∑—É—è –∫–Ω–æ–ø–∫–∏ –Ω–∏–∂–µ.",
        reply_markup=get_video_duration_keyboard(duration_options),
    )


@router.message(BotStates.video_select_resolution)
async def wait_resolution_selection(message: Message, state: FSMContext):
    """–ù–∞–ø–æ–º–∏–Ω–∞–µ–º –≤—ã–±—Ä–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ, –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–∏—à–µ—Ç –≤–º–µ—Å—Ç–æ –∫–Ω–æ–ø–æ–∫."""
    data = await state.get_data()
    options = data.get('resolution_options') or ["720p", "1080p"]
    await message.answer(
        "–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é –∫–Ω–æ–ø–æ–∫ –Ω–∏–∂–µ.",
        reply_markup=get_video_resolution_keyboard(options),
    )


@router.callback_query(
    StateFilter("*"),
    F.data.startswith("video_format:"),
)
async def set_video_format(callback: CallbackQuery, state: FSMContext):
    """–°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω –∏ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–±–æ—Ä—É –ø—Ä–æ–º—Ç–∞."""
    await callback.answer()

    ratio_raw = callback.data.split(":", maxsplit=1)[1]
    aspect_ratio = ratio_raw.replace("_", ":") if "_" in ratio_raw else ratio_raw

    data = await state.get_data()
    # –ï—Å–ª–∏ —Å—Ç–µ–π—Ç –ø—É—Å—Ç–æ–π (–ø–æ—Ç–µ—Ä—è–Ω), –∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–∂–∞–ª –∫–Ω–æ–ø–∫—É —Ñ–æ—Ä–º–∞—Ç–∞
    if not data:
        await callback.message.answer(
            "‚ö†Ô∏è –°–µ—Å—Å–∏—è —É—Å—Ç–∞—Ä–µ–ª–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—á–Ω–∏—Ç–µ —Å–æ–∑–¥–∞–Ω–∏–µ –≤–∏–¥–µ–æ –∑–∞–Ω–æ–≤–æ.",
            reply_markup=get_main_menu_inline_keyboard()
        )
        return

    supports_images = data.get('supports_images', False)
    duration_options = data.get('duration_options') or []
    default_duration = data.get('default_duration')

    await state.update_data(
        selected_aspect_ratio=aspect_ratio,
        generation_type='text2video',
        input_image_file_id=None,
        input_image_mime_type=None,
        selected_duration=None,
    )

    if duration_options:
        await state.set_state(BotStates.video_select_duration)
        await callback.message.answer(
            "–í—ã–±–µ—Ä–∏—Ç–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–æ–ª–∏–∫–∞:",
            reply_markup=get_video_duration_keyboard(duration_options),
        )
        return

    selected_duration = data.get('selected_duration') or default_duration
    await state.update_data(selected_duration=selected_duration)

    if await _maybe_prompt_resolution(callback.message, state):
        return

    resolution_value = data.get('selected_resolution') or data.get('default_resolution')
    await _prompt_user_for_description(
        callback.message,
        supports_images=supports_images,
        aspect_ratio=aspect_ratio,
        duration=selected_duration,
        resolution=resolution_value,
        is_sora=data.get('is_sora', False),
    )
    await state.set_state(BotStates.video_wait_prompt)


@router.callback_query(
    StateFilter("*"),
    F.data.startswith("video_duration:"),
)
async def set_video_duration(callback: CallbackQuery, state: FSMContext):
    """–°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–±–æ—Ä—É –ø—Ä–æ–º—Ç–∞."""
    await callback.answer()

    data = await state.get_data()
    if not data:
        await callback.message.answer(
            "‚ö†Ô∏è –°–µ—Å—Å–∏—è —É—Å—Ç–∞—Ä–µ–ª–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—á–Ω–∏—Ç–µ —Å–æ–∑–¥–∞–Ω–∏–µ –≤–∏–¥–µ–æ –∑–∞–Ω–æ–≤–æ.",
            reply_markup=get_main_menu_inline_keyboard()
        )
        return

    duration_options = data.get('duration_options') or []
    keyboard_options = duration_options or [data.get('default_duration', 8)]

    try:
        duration_value = int(callback.data.split(":", maxsplit=1)[1])
    except (ValueError, IndexError):
        await callback.message.answer(
            "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.",
            reply_markup=get_video_duration_keyboard(keyboard_options),
        )
        return

    if duration_options and duration_value not in duration_options:
        await callback.message.answer(
            "–≠—Ç–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –∏–∑ —Å–ø–∏—Å–∫–∞ –Ω–∏–∂–µ.",
            reply_markup=get_video_duration_keyboard(duration_options),
        )
        return

    supports_images = data.get('supports_images', False)
    aspect_ratio = data.get('selected_aspect_ratio', '16:9')

    await state.update_data(selected_duration=duration_value)

    if await _maybe_prompt_resolution(callback.message, state):
        return

    resolution_value = data.get('selected_resolution') or data.get('default_resolution')
    await _prompt_user_for_description(
        callback.message,
        supports_images=supports_images,
        aspect_ratio=aspect_ratio,
        duration=duration_value,
        resolution=resolution_value,
        is_sora=data.get('is_sora', False),
    )

    await state.set_state(BotStates.video_wait_prompt)


@router.callback_query(
    StateFilter("*"),
    F.data.startswith("video_resolution:"),
)
async def set_video_resolution(callback: CallbackQuery, state: FSMContext):
    """–°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∏ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–±–æ—Ä—É –ø—Ä–æ–º—Ç–∞."""
    await callback.answer()

    data = await state.get_data()
    if not data:
         await callback.message.answer(
            "‚ö†Ô∏è –°–µ—Å—Å–∏—è —É—Å—Ç–∞—Ä–µ–ª–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—á–Ω–∏—Ç–µ —Å–æ–∑–¥–∞–Ω–∏–µ –≤–∏–¥–µ–æ –∑–∞–Ω–æ–≤–æ.",
            reply_markup=get_main_menu_inline_keyboard()
        )
         return
         
    options = [opt.lower() for opt in (data.get('resolution_options') or [])]

    try:
        value = callback.data.split(":", maxsplit=1)[1].lower()
    except (ValueError, IndexError):
        await callback.message.answer(
            "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≤—ã–±—Ä–∞–Ω–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.",
            reply_markup=get_video_resolution_keyboard(data.get('resolution_options') or ["720p", "1080p"]),
        )
        return

    if options and value not in options:
        await callback.message.answer(
            "–≠—Ç–æ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ. –í—ã–±–µ—Ä–∏—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç –∏–∑ —Å–ø–∏—Å–∫–∞.",
            reply_markup=get_video_resolution_keyboard(data.get('resolution_options') or ["720p", "1080p"]),
        )
        return

    await state.update_data(selected_resolution=value)

    supports_images = data.get('supports_images', False)
    aspect_ratio = data.get('selected_aspect_ratio', '16:9')
    duration = data.get('selected_duration') or data.get('default_duration')
    resolution_value = value

    await _prompt_user_for_description(
        callback.message,
        supports_images=supports_images,
        aspect_ratio=aspect_ratio,
        duration=duration,
        resolution=resolution_value,
        is_sora=data.get('is_sora', False),
    )
    await state.set_state(BotStates.video_wait_prompt)


@router.message(BotStates.video_wait_prompt, F.photo)
async def receive_image_for_video(message: Message, state: FSMContext):
    """
    –ü–æ–ª—É—á–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ (image2video)
    """
    data = await state.get_data()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª–∏ –º–æ–¥–µ–ª—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    if not data.get('supports_images'):
        await message.answer(
            "‚ùå –≠—Ç–∞ –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.\n"
            "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ.",
            reply_markup=get_main_menu_inline_keyboard()
        )
        return

    # –ü–æ–ª—É—á–∞–µ–º file_id —Å–∞–º–æ–≥–æ –±–æ–ª—å—à–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–æ—Ç–æ
    photo = message.photo[-1]

    resolution_value = data.get('selected_resolution') or data.get('default_resolution')
    aspect_ratio = data.get('selected_aspect_ratio') or data.get('default_aspect_ratio')
    hint_text = _format_image_hint_text(
        _calculate_image_size_hint(
            supports_images=True,
            is_sora=data.get('is_sora', False),
            resolution=resolution_value,
            aspect_ratio=aspect_ratio,
        )
    )

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏
    await state.update_data(
        input_image_file_id=photo.file_id,
        input_image_mime_type='image/jpeg'
    )

    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
    text = (
        "‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ!\n\n"
        "–¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."
    )
    if hint_text:
        text += f"\n\n‚ÑπÔ∏è {hint_text}"

    await message.answer(text, reply_markup=get_cancel_keyboard())

    # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è –ø—Ä–æ–º—Ç–∞ –¥–ª—è image2video
    await state.set_state(BotStates.video_wait_prompt)
    await state.update_data(generation_type='image2video')


@router.message(BotStates.video_wait_prompt, F.document)
async def receive_document_for_video(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ/–≤–∏–¥–µ–æ) –∫–∞–∫ –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–ª—è image2video."""
    data = await state.get_data()
    if not data.get('supports_images'):
        await message.answer(
            "‚ùå –≠—Ç–∞ –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã.\n"
            "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ.",
            reply_markup=get_main_menu_inline_keyboard()
        )
        return

    document = message.document
    if not document:
        await message.answer(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ–∞–π–ª. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.",
            reply_markup=get_cancel_keyboard()
        )
        return

    allowed_types = {"image/jpeg", "image/png", "image/webp", "video/mp4"}
    mime_type = (document.mime_type or "").lower()
    if mime_type not in allowed_types:
        await message.answer(
            "‚ö†Ô∏è –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã JPG, PNG, WEBP –∏–ª–∏ MP4.\n"
            "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –¥—Ä—É–≥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ —Ñ–æ—Ç–æ.",
            reply_markup=get_cancel_keyboard()
        )
        return

    await state.update_data(
        input_image_file_id=document.file_id,
        input_image_mime_type=mime_type,
        generation_type='image2video',
    )

    resolution_value = data.get('selected_resolution') or data.get('default_resolution')
    aspect_ratio = data.get('selected_aspect_ratio') or data.get('default_aspect_ratio')
    hint_text = _format_image_hint_text(
        _calculate_image_size_hint(
            supports_images=True,
            is_sora=data.get('is_sora', False),
            resolution=resolution_value,
            aspect_ratio=aspect_ratio,
        )
    )

    text = (
        "‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω!\n\n"
        "–¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ, —á—Ç–æ–±—ã –∑–∞–ø—É—Å—Ç–∏—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é."
    )
    if hint_text:
        text += f"\n\n‚ÑπÔ∏è {hint_text}"

    await message.answer(text, reply_markup=get_cancel_keyboard())


@router.message(BotStates.video_wait_prompt, F.text)
async def handle_video_prompt(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ (txt2video / img2video)."""
    data = await state.get_data()
    prompt = message.text.strip()

    try:
        model = await sync_to_async(AIModel.objects.get)(id=data['model_id'])
    except (KeyError, AIModel.DoesNotExist):
        await message.answer(
            "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –º–æ–¥–µ–ª—å. –ù–∞—á–Ω–∏—Ç–µ –∑–∞–Ω–æ–≤–æ —Å /start.",
            reply_markup=get_main_menu_inline_keyboard()
        )
        await state.clear()
        return

    if len(prompt) > model.max_prompt_length:
        await message.answer(
            f"‚ùå –ü—Ä–æ–º—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π!\n"
            f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {model.max_prompt_length} —Å–∏–º–≤–æ–ª–æ–≤\n"
            f"–í–∞—à –ø—Ä–æ–º—Ç: {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤",
            reply_markup=get_main_menu_inline_keyboard()
        )
        return

    generation_type = data.get('generation_type', 'text2video')
    default_duration = data.get('default_duration') or model.default_params.get('duration') or 8
    selected_duration = data.get('selected_duration') or default_duration
    default_resolution = data.get('default_resolution') or model.default_params.get('resolution') or '720p'
    default_aspect_ratio = data.get('default_aspect_ratio') or model.default_params.get('aspect_ratio') or '16:9'
    selected_aspect_ratio = data.get('selected_aspect_ratio') or default_aspect_ratio
    selected_resolution = data.get('selected_resolution') or default_resolution

    generation_params = {
        'duration': selected_duration,
        'resolution': selected_resolution,
        'aspect_ratio': selected_aspect_ratio,
    }

    input_image_file_id = data.get('input_image_file_id')
    input_image_mime_type = data.get('input_image_mime_type', 'image/jpeg')
    source_media = {}

    if generation_type == 'image2video' and input_image_file_id:
        generation_params['input_image_file_id'] = input_image_file_id
        generation_params['input_image_mime_type'] = input_image_mime_type
        source_media['telegram_file_id'] = input_image_file_id
        source_media['mime_type'] = input_image_mime_type
    else:
        generation_type = 'text2video'

    user = await sync_to_async(TgUser.objects.get)(chat_id=message.from_user.id)

    try:
        gen_request = await sync_to_async(GenerationService.create_generation_request)(
            user=user,
            ai_model=model,
            prompt=prompt,
            quantity=1,
            generation_type=generation_type,
            generation_params=generation_params,
            duration=selected_duration,
            video_resolution=selected_resolution,
            aspect_ratio=selected_aspect_ratio,
            input_image_file_id=input_image_file_id,
            source_media=source_media
        )
    except InsufficientBalanceError as exc:
        await message.answer(str(exc), reply_markup=get_main_menu_inline_keyboard())
        await state.clear()
        return
    except ValueError as exc:
        await message.answer(str(exc), reply_markup=get_main_menu_inline_keyboard())
        await state.clear()
        return
    except Exception as exc:
        await message.answer(
            f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {exc}",
            reply_markup=get_main_menu_inline_keyboard()
        )
        await ErrorTracker.alog(
            origin=BotErrorEvent.Origin.TELEGRAM,
            severity=BotErrorEvent.Severity.WARNING,
            handler="video_generation.receive_video_prompt",
            chat_id=message.chat.id,
            payload={
                "generation_type": generation_type,
                "model_id": data.get("model_id"),
                "duration": selected_duration,
                "resolution": selected_resolution,
                "aspect_ratio": selected_aspect_ratio,
            },
            exc=exc,
        )
        await state.clear()
        return

    await _send_generation_start_message(
        message,
        get_generation_start_message(
            model=model.display_name,
            mode=generation_type,
            aspect_ratio=selected_aspect_ratio,
            resolution=selected_resolution,
            duration=selected_duration,
            prompt=prompt,
        ),
    )

    generate_video_task.delay(gen_request.id)
    await state.clear()


@router.callback_query(StateFilter("*"), F.data.startswith("extend_video:"))
async def prompt_video_extension(callback: CallbackQuery, state: FSMContext):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∫ –ø—Ä–æ–¥–ª–µ–Ω–∏—é –≤–∏–¥–µ–æ."""
    await callback.answer()
    
    # –û—á–∏—â–∞–µ–º —Å—Ç–µ–π—Ç, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ –Ω–∞—á–∞–ª–æ –Ω–æ–≤–æ–≥–æ —Ñ–ª–æ—É (–ø—Ä–æ–¥–ª–µ–Ω–∏—è)
    await state.clear()

    try:
        request_id = int(callback.data.split(":", maxsplit=1)[1])
    except (ValueError, IndexError):
        await callback.message.answer(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –∫–∞–∫–æ–µ –≤–∏–¥–µ–æ –ø—Ä–æ–¥–ª–∏—Ç—å.",
            reply_markup=get_main_menu_inline_keyboard()
        )
        return

    try:
        gen_request = await sync_to_async(
            GenRequest.objects.select_related("ai_model", "user").get
        )(id=request_id)
    except GenRequest.DoesNotExist:
        await callback.message.answer(
            "–≠—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –±–æ–ª—å—à–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.",
            reply_markup=get_main_menu_inline_keyboard()
        )
        return

    if gen_request.chat_id != callback.from_user.id:
        await callback.answer("–ú–æ–∂–Ω–æ –ø—Ä–æ–¥–ª–∏—Ç—å —Ç–æ–ª—å–∫–æ —Å–≤–æ–∏ –≤–∏–¥–µ–æ.", show_alert=True)
        return

    if gen_request.status != "done" or not gen_request.result_urls:
        await callback.message.answer(
            "–í–∏–¥–µ–æ –µ—â—ë –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á—É—Ç—å –ø–æ–∑–∂–µ.",
            reply_markup=get_main_menu_inline_keyboard()
        )
        return

    model = gen_request.ai_model
    if not model:
        await callback.message.answer(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤–æ–µ –≤–∏–¥–µ–æ.",
            reply_markup=get_main_menu_inline_keyboard()
        )
        return
    if model.provider != "veo":
        await callback.answer("–ü—Ä–æ–¥–ª–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ –¥–ª—è Veo.", show_alert=True)
        return

    aspect_ratio = gen_request.aspect_ratio or gen_request.generation_params.get("aspect_ratio") or "–Ω–µ —É–∫–∞–∑–∞–Ω"
    base_price = await sync_to_async(get_base_price_tokens)(model)
    cost_text = f"‚ö° –°—Ç–æ–∏–º–æ—Å—Ç—å –ø—Ä–æ–¥–ª–µ–Ω–∏—è: {base_price:.2f} —Ç–æ–∫–µ–Ω–æ–≤."

    await state.update_data(
        extend_parent_request_id=gen_request.id,
    )
    await state.set_state(BotStates.video_extend_prompt)

    prompt_text = (
        "–ú–æ–∂–Ω–æ –ø—Ä–æ–¥–ª–∏—Ç—å –≤–∞—à —Ä–æ–ª–∏–∫ –µ—â—ë –Ω–∞ 8 —Å–µ–∫—É–Ω–¥.\n\n"
        f"–ú–æ–¥–µ–ª—å: {model.display_name}\n"
        f"–ê—Å–ø–µ–∫—Ç: {aspect_ratio}\n"
        f"{cost_text}\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ ¬´–û—Ç–º–µ–Ω–∞¬ª."
    )

    await callback.message.answer(prompt_text, reply_markup=get_cancel_keyboard())


@router.message(BotStates.video_extend_prompt, F.text)
async def handle_video_extension_prompt(message: Message, state: FSMContext):
    """–ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–¥–ª–µ–Ω–∏—è –≤–∏–¥–µ–æ –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –∑–∞–¥–∞—á—É."""
    text = message.text.strip()
    if text.lower() in {"–æ—Ç–º–µ–Ω–∞", "cancel"}:
        await state.clear()
        await message.answer(
            "–ü—Ä–æ–¥–ª–µ–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ.",
            reply_markup=get_main_menu_inline_keyboard()
        )
        return

    data = await state.get_data()
    parent_request_id = data.get("extend_parent_request_id")

    if not parent_request_id:
        await message.answer(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏—Å—Ö–æ–¥–Ω–æ–µ –≤–∏–¥–µ–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.",
            reply_markup=get_main_menu_inline_keyboard()
        )
        await state.clear()
        return

    try:
        parent_request = await sync_to_async(
            GenRequest.objects.select_related("ai_model", "user").get
        )(id=parent_request_id)
    except GenRequest.DoesNotExist:
        await message.answer(
            "–≠—Ç–æ –≤–∏–¥–µ–æ –±–æ–ª—å—à–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ –¥–ª—è –ø—Ä–æ–¥–ª–µ–Ω–∏—è.",
            reply_markup=get_main_menu_inline_keyboard()
        )
        await state.clear()
        return

    if parent_request.chat_id != message.from_user.id:
        await message.answer(
            "–ú–æ–∂–Ω–æ –ø—Ä–æ–¥–ª–∏—Ç—å —Ç–æ–ª—å–∫–æ —Å–≤–æ–∏ –≤–∏–¥–µ–æ.",
            reply_markup=get_main_menu_inline_keyboard()
        )
        await state.clear()
        return

    model = parent_request.ai_model
    if not model:
        await message.answer(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –Ω–∞—á–∞—Ç—å –Ω–æ–≤—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é.",
            reply_markup=get_main_menu_inline_keyboard()
        )
        await state.clear()
        return

    if len(text) > model.max_prompt_length:
        await message.answer(
            f"‚ùå –ü—Ä–æ–º—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π! –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {model.max_prompt_length} —Å–∏–º–≤–æ–ª–æ–≤.",
            reply_markup=get_cancel_keyboard()
        )
        return

    if not parent_request.result_urls:
        await message.answer(
            "–ò—Å—Ö–æ–¥–Ω–æ–µ –≤–∏–¥–µ–æ –µ—â—ë –Ω–µ –≥–æ—Ç–æ–≤–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á—É—Ç—å –ø–æ–∑–∂–µ.",
            reply_markup=get_main_menu_inline_keyboard()
        )
        await state.clear()
        return

    aspect_ratio = (
        parent_request.aspect_ratio
        or parent_request.generation_params.get("aspect_ratio")
        or (model.default_params or {}).get("aspect_ratio")
        or "16:9"
    )
    resolution = (
        parent_request.video_resolution
        or parent_request.generation_params.get("resolution")
        or (model.default_params or {}).get("resolution")
        or "720p"
    )

    generation_params = {
        "duration": 8,
        "aspect_ratio": aspect_ratio,
        "resolution": resolution,
        "extend_parent_request_id": parent_request.id,
    }
    source_media = {
        "parent_request_id": parent_request.id,
        "parent_result_url": parent_request.result_urls[0],
    }

    try:
        gen_request = await sync_to_async(GenerationService.create_generation_request)(
            user=parent_request.user,
            ai_model=model,
            prompt=text,
            quantity=1,
            generation_type='image2video',
            generation_params=generation_params,
            duration=8,
            video_resolution=resolution,
            aspect_ratio=aspect_ratio,
            source_media=source_media,
            parent_request=parent_request,
        )
    except InsufficientBalanceError as exc:
        await message.answer(str(exc), reply_markup=get_main_menu_inline_keyboard())
        await state.clear()
        return
    except ValueError as exc:
        await message.answer(str(exc), reply_markup=get_main_menu_inline_keyboard())
        await state.clear()
        return
    except Exception as exc:
        await message.answer(
            f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {exc}",
            reply_markup=get_main_menu_inline_keyboard()
        )
        await ErrorTracker.alog(
            origin=BotErrorEvent.Origin.TELEGRAM,
            severity=BotErrorEvent.Severity.WARNING,
            handler="video_generation.extend_video_prompt",
            chat_id=message.chat.id,
            payload={
                "parent_request_id": parent_request.id if parent_request else None,
                "model_id": model.id if model else None,
                "prompt_length": len(text) if text else 0,
            },
            exc=exc,
        )
        await state.clear()
        return

    await _send_generation_start_message(
        message,
        get_generation_start_message(
            model=model.display_name if model else "‚Äî",
            mode="image2video",
            aspect_ratio=aspect_ratio,
            resolution=resolution,
            duration=8,
            prompt=text,
        ),
    )

    extend_video_task.delay(gen_request.id)
    await state.clear()


@router.message(BotStates.video_extend_prompt)
async def remind_extension_prompt(message: Message):
    """–ï—Å–ª–∏ –ø—Ä–∏–ª–µ—Ç–µ–ª–æ —á—Ç–æ-—Ç–æ –∫—Ä–æ–º–µ —Ç–µ–∫—Å—Ç–∞ –≤–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –ø—Ä–æ–º—Ç–∞."""
    await message.answer(
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º—Ç –¥–ª—è –ø—Ä–æ–¥–ª–µ–Ω–∏—è –≤–∏–¥–µ–æ –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ ¬´–û—Ç–º–µ–Ω–∞¬ª.",
        reply_markup=get_cancel_keyboard()
    )


@router.callback_query(StateFilter("*"), F.data == "main_menu")
async def handle_main_menu_callback(callback: CallbackQuery, state: FSMContext):
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ inline –∫–Ω–æ–ø–∫–∏ "–ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é"
    """
    await callback.answer()

    # –û—á–∏—â–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    await state.clear()
    await state.set_state(BotStates.main_menu)

    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –≥–ª–∞–≤–Ω–æ–≥–æ –º–µ–Ω—é –∏–∑ menu.py
    from django.conf import settings
    from botapp.keyboards import get_main_menu_keyboard

    PAYMENT_URL = getattr(settings, 'PAYMENT_MINI_APP_URL', 'https://example.com/payment')

    await callback.message.answer(
        "–í—ã–±–µ—Ä–∏—Ç–µ –Ω—É–∂–Ω–æ–µ  –¥–µ–π—Å—Ç–≤–∏–µ –Ω–∞–∂–∞–≤ –Ω–∞ –∫–Ω–æ–ø–∫—É –≤ –º–µ–Ω—é üëá",
        reply_markup=get_main_menu_keyboard(PAYMENT_URL)
    )
